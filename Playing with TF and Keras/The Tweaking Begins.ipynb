{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I made quite a bit of progress with my initial foray. While the test accuracy of the previous model was 92.3%. I am going to attempt to 'overclock' the model by: \n",
    "<ul>\n",
    "<li> Increasing the number of hidden layers </li>\n",
    "<li> Changing the Optimizer to Adam </li>\n",
    "<li> Experiment with Dropout</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "\n",
    "#Training Parameters \n",
    "EPOCHS = 150 \n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10\n",
    "# N_HIDDEN = 128\n",
    "HIDDEN_1 = 300\n",
    "HIDDEN_2 = 500\n",
    "HIDDEN_3 = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading the dataset \n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000,RESHAPED)\n",
    "X_test = X_test.reshape(10000,RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000 train samples\n10000 test samples\n"
    }
   ],
   "source": [
    "#normalizing inputs\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model gangan \n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(HIDDEN_1,input_shape=(RESHAPED,),name='dense_layer', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(HIDDEN_2,input_shape=(RESHAPED,),name='dense_layer_2', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dense(HIDDEN_3,input_shape=(RESHAPED,),name='dense_layer_3', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,),name='dense_layer_4', \n",
    "\t\tactivation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_layer (Dense)          (None, 300)               235500    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 300)               0         \n_________________________________________________________________\ndense_layer_2 (Dense)        (None, 500)               150500    \n_________________________________________________________________\ndense_layer_3 (Dense)        (None, 100)               50100     \n_________________________________________________________________\ndense_layer_4 (Dense)        (None, 10)                1010      \n=================================================================\nTotal params: 437,110\nTrainable params: 437,110\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/65\n375/375 [==============================] - 3s 7ms/step - loss: 0.3194 - accuracy: 0.9031 - val_loss: 0.1250 - val_accuracy: 0.9622\nEpoch 2/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.9581 - val_loss: 0.0993 - val_accuracy: 0.9706\nEpoch 3/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 0.0934 - val_accuracy: 0.9710\nEpoch 4/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 0.0836 - val_accuracy: 0.9749\nEpoch 5/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.0762 - val_accuracy: 0.9775\nEpoch 6/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 0.0817 - val_accuracy: 0.9761\nEpoch 7/65\n375/375 [==============================] - 2s 6ms/step - loss: 0.0535 - accuracy: 0.9825 - val_loss: 0.0853 - val_accuracy: 0.9761\nEpoch 8/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.9835 - val_loss: 0.0786 - val_accuracy: 0.9778\nEpoch 9/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.0859 - val_accuracy: 0.9772\nEpoch 10/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.0781 - val_accuracy: 0.9802\nEpoch 11/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.0715 - val_accuracy: 0.9810\nEpoch 12/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.0776 - val_accuracy: 0.9788\nEpoch 13/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0803 - val_accuracy: 0.9791\nEpoch 14/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0765 - val_accuracy: 0.9804\nEpoch 15/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.0979 - val_accuracy: 0.9780\nEpoch 16/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0790 - val_accuracy: 0.9812\nEpoch 17/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.0791 - val_accuracy: 0.9806\nEpoch 18/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.0821 - val_accuracy: 0.9808\nEpoch 19/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0987 - val_accuracy: 0.9782\nEpoch 20/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0847 - val_accuracy: 0.9794\nEpoch 21/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.0811 - val_accuracy: 0.9815\nEpoch 22/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0913 - val_accuracy: 0.9793\nEpoch 23/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0737 - val_accuracy: 0.9831\nEpoch 24/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.0751 - val_accuracy: 0.9824\nEpoch 25/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0844 - val_accuracy: 0.9815\nEpoch 26/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0837 - val_accuracy: 0.9820\nEpoch 27/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0838 - val_accuracy: 0.9823\nEpoch 28/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0834 - val_accuracy: 0.9812\nEpoch 29/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0939 - val_accuracy: 0.9811\nEpoch 30/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0914 - val_accuracy: 0.9808\nEpoch 31/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0897 - val_accuracy: 0.9820\nEpoch 32/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0906 - val_accuracy: 0.9811\nEpoch 33/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0886 - val_accuracy: 0.9817\nEpoch 34/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0784 - val_accuracy: 0.9832\nEpoch 35/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0882 - val_accuracy: 0.9797\nEpoch 36/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0857 - val_accuracy: 0.9837\nEpoch 37/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0941 - val_accuracy: 0.9822\nEpoch 38/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0926 - val_accuracy: 0.9813\nEpoch 39/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0870 - val_accuracy: 0.9825\nEpoch 40/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.0917 - val_accuracy: 0.9806\nEpoch 41/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0901 - val_accuracy: 0.9806\nEpoch 42/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0935 - val_accuracy: 0.9813\nEpoch 43/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0916 - val_accuracy: 0.9814\nEpoch 44/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0796 - val_accuracy: 0.9849\nEpoch 45/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0953 - val_accuracy: 0.9812\nEpoch 46/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0814 - val_accuracy: 0.9835\nEpoch 47/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0935 - val_accuracy: 0.9819\nEpoch 48/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0846 - val_accuracy: 0.9828\nEpoch 49/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0850 - val_accuracy: 0.9833\nEpoch 50/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0882 - val_accuracy: 0.9835\nEpoch 51/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0945 - val_accuracy: 0.9815\nEpoch 52/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0986 - val_accuracy: 0.9820\nEpoch 53/65\n375/375 [==============================] - 3s 7ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0934 - val_accuracy: 0.9812\nEpoch 54/65\n375/375 [==============================] - 3s 7ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0934 - val_accuracy: 0.9828\nEpoch 55/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0890 - val_accuracy: 0.9822\nEpoch 56/65\n375/375 [==============================] - 2s 6ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0914 - val_accuracy: 0.9837\nEpoch 57/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0873 - val_accuracy: 0.9843\nEpoch 58/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0975 - val_accuracy: 0.9820\nEpoch 59/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.0924 - val_accuracy: 0.9825\nEpoch 60/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.1050 - val_accuracy: 0.9814\nEpoch 61/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0870 - val_accuracy: 0.9833\nEpoch 62/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0928 - val_accuracy: 0.9839\nEpoch 63/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0873 - val_accuracy: 0.9837\nEpoch 64/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0983 - val_accuracy: 0.9820\nEpoch 65/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0988 - val_accuracy: 0.9826\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1637392b0>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#Training the model \n",
    "model.fit(X_train,Y_train,batch_size=BATCH_SIZE,epochs=EPOCHS,verbose=VERBOSE,validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9832\nTest accuracy: 0.9832000136375427\n"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting out with test accuracy at 92.3% and then getting 98.1% wth 55 Epoch isn't bad at all. It remains to test the limits of convergence, but it's a decent foray so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}