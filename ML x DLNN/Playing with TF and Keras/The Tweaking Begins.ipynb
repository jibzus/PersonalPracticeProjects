{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I made quite a bit of progress with my initial foray. While the test accuracy of the previous model was 92.3%. I am going to attempt to 'overclock' the model by: \n",
    "<ul>\n",
    "<li> Increasing the number of hidden layers </li>\n",
    "<li> Changing the Optimizer to Adam </li>\n",
    "<li> Experiment with Dropout</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "\n",
    "#Training Parameters \n",
    "EPOCHS = 150 \n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10\n",
    "# N_HIDDEN = 128\n",
    "HIDDEN_1 = 300\n",
    "HIDDEN_2 = 500\n",
    "HIDDEN_3 = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading the dataset \n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000,RESHAPED)\n",
    "X_test = X_test.reshape(10000,RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000 train samples\n10000 test samples\n"
    }
   ],
   "source": [
    "#normalizing inputs\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model gangan \n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(HIDDEN_1,input_shape=(RESHAPED,),name='dense_layer', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(HIDDEN_2,input_shape=(RESHAPED,),name='dense_layer_2', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dense(HIDDEN_3,input_shape=(RESHAPED,),name='dense_layer_3', \n",
    "\t\tactivation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES,input_shape=(RESHAPED,),name='dense_layer_4', \n",
    "\t\tactivation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_layer (Dense)          (None, 300)               235500    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 300)               0         \n_________________________________________________________________\ndense_layer_2 (Dense)        (None, 500)               150500    \n_________________________________________________________________\ndense_layer_3 (Dense)        (None, 100)               50100     \n_________________________________________________________________\ndense_layer_4 (Dense)        (None, 10)                1010      \n=================================================================\nTotal params: 437,110\nTrainable params: 437,110\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0931 - val_accuracy: 0.9839\nEpoch 2/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1008 - val_accuracy: 0.9821\nEpoch 3/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0867 - val_accuracy: 0.9839\nEpoch 4/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0978 - val_accuracy: 0.9818\nEpoch 5/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0964 - val_accuracy: 0.9836\nEpoch 6/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1096 - val_accuracy: 0.9821\nEpoch 7/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1010 - val_accuracy: 0.9822\nEpoch 8/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0935 - val_accuracy: 0.9839\nEpoch 9/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0881 - val_accuracy: 0.9835\nEpoch 10/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1066 - val_accuracy: 0.9826\nEpoch 11/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0941 - val_accuracy: 0.9835\nEpoch 12/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0893 - val_accuracy: 0.9839\nEpoch 13/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0955 - val_accuracy: 0.9833\nEpoch 14/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0869 - val_accuracy: 0.9837\nEpoch 15/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0879 - val_accuracy: 0.9843\nEpoch 16/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0925 - val_accuracy: 0.9841\nEpoch 17/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0901 - val_accuracy: 0.9849\nEpoch 18/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0967 - val_accuracy: 0.9835\nEpoch 19/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1010 - val_accuracy: 0.9823\nEpoch 20/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0952 - val_accuracy: 0.9827\nEpoch 21/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0982 - val_accuracy: 0.9835\nEpoch 22/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0909 - val_accuracy: 0.9837\nEpoch 23/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1029 - val_accuracy: 0.9829\nEpoch 24/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0988 - val_accuracy: 0.9830\nEpoch 25/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0961 - val_accuracy: 0.9848\nEpoch 26/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0946 - val_accuracy: 0.9847\nEpoch 27/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0904 - val_accuracy: 0.9835\nEpoch 28/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0959 - val_accuracy: 0.9831\nEpoch 29/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0958 - val_accuracy: 0.9827\nEpoch 30/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1047 - val_accuracy: 0.9829\nEpoch 31/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1040 - val_accuracy: 0.9836\nEpoch 32/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1087 - val_accuracy: 0.9824\nEpoch 33/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1007 - val_accuracy: 0.9837\nEpoch 34/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0952 - val_accuracy: 0.9834\nEpoch 35/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0978 - val_accuracy: 0.9838\nEpoch 36/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1036 - val_accuracy: 0.9838\nEpoch 37/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1088 - val_accuracy: 0.9839\nEpoch 38/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1063 - val_accuracy: 0.9826\nEpoch 39/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.1013 - val_accuracy: 0.9849\nEpoch 40/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1020 - val_accuracy: 0.9834\nEpoch 41/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1027 - val_accuracy: 0.9834\nEpoch 42/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1049 - val_accuracy: 0.9836\nEpoch 43/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1038 - val_accuracy: 0.9837\nEpoch 44/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1040 - val_accuracy: 0.9843\nEpoch 45/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0992 - val_accuracy: 0.9837\nEpoch 46/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.1050 - val_accuracy: 0.9827\nEpoch 47/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1040 - val_accuracy: 0.9837\nEpoch 48/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1022 - val_accuracy: 0.9836\nEpoch 49/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0956 - val_accuracy: 0.9838\nEpoch 50/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1155 - val_accuracy: 0.9821\nEpoch 51/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0938 - val_accuracy: 0.9838\nEpoch 52/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1017 - val_accuracy: 0.9830\nEpoch 53/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1122 - val_accuracy: 0.9828\nEpoch 54/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0981 - val_accuracy: 0.9847\nEpoch 55/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1058 - val_accuracy: 0.9843\nEpoch 56/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.1128 - val_accuracy: 0.9835\nEpoch 57/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1015 - val_accuracy: 0.9849\nEpoch 58/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0954 - val_accuracy: 0.9844\nEpoch 59/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1021 - val_accuracy: 0.9826\nEpoch 60/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1063 - val_accuracy: 0.9844\nEpoch 61/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1048 - val_accuracy: 0.9837\nEpoch 62/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1169 - val_accuracy: 0.9839\nEpoch 63/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1249 - val_accuracy: 0.9833\nEpoch 64/65\n375/375 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1106 - val_accuracy: 0.9838\nEpoch 65/65\n375/375 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1083 - val_accuracy: 0.9837\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14a453cf8>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#Training the model \n",
    "model.fit(X_train,Y_train,batch_size=BATCH_SIZE,epochs=EPOCHS,verbose=VERBOSE,validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9843\nTest accuracy: 0.9843000173568726\n"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting out with test accuracy at 92.3% and then getting 98.1% wth 55 Epoch isn't bad at all. It remains to test the limits of convergence, but it's a decent foray so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}